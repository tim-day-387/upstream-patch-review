UPDATE ROOT IMAGE ... done
P+q6E616D65\[6n[32766;32766H[6n[!p]104[?7h[1G[0J]3008;start=49731cde928b4fb087bd63e0190d0fae;user=root;hostname=lustre-bot-kvm;machineid=a79734507b7a4cd085276a3f8d51378f;bootid=da14c47c2d044761967527c558b4403e;pid=1;pidfdid=2;comm=systemd;type=boot\Kernel version: 6.14.0-ktest-171ff02d8a-20260217
hook init_noop

Running tests llmount

========= TEST   llmount

SETUP LUSTRE ... libcfs: loading out-of-tree module taints kernel.
libcfs: HW NUMA nodes: 1, HW CPU cores: 16, npartitions: 1
Lustre: Lustre: Build Version: 2.17.50_152_g171ff02
LNet: Added LNI 10.0.2.15@tcp [8/256/0/180]
Lustre: Echo OBD driver; http://www.lustre.org/
Lustre: DEBUG MARKER: lustre-bot-kvm: executing set_hostid
Lustre: lustre-MDT0000: mounting server target with '-t lustre' deprecated, use '-t lustre_tgt'
Lustre: ctl-lustre-MDT0000: No data found on store. Initialize space.
Lustre: lustre-MDT0000: new disk, initializing
Lustre: lustre-MDT0000: Imperative Recovery not enabled, recovery window 300-900
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000200000400-0x0000000240000400]:0:mdt
mount.lustre (2910) used greatest stack depth: 24144 bytes left
Lustre: Modifying parameter general.debug_raw_pointers=Y in log params
mount.lustre (3052) used greatest stack depth: 23648 bytes left
mount.lustre (3168) used greatest stack depth: 23584 bytes left
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000240000400-0x0000000280000400]:0:ost
Lustre: cli-lustre-OST0000-super: Allocated super-sequence [0x0000000240000400-0x0000000280000400]:0:ost]
Lustre: lustre-OST0000-osc-MDT0000: update sequence from 0x100000000 to 0x240000400
Lustre: lustre-OST0001-osc-MDT0000: update sequence from 0x100010000 to 0x280000400
Lustre: lustre-MDT0000: local client 8005922a-d93f-43d2-9226-cc51a28f3946 w/o recovery
Lustre: client wants to enable acl, but mdt not!
Lustre: Mounted lustre-client
Lustre: DEBUG MARKER: Using TIMEOUT=100
Lustre: Setting parameter general.lod.*.mdt_hash=crush in log params
done
CLEANUP LUSTRE ... Lustre: setting import lustre-MDT0000_UUID INACTIVE by administrator request
Lustre: Unmounted lustre-client
Lustre: server umount lustre-MDT0000 complete
LustreError: 2915:0:(ldlm_lockd.c:2564:ldlm_cancel_handler()) ldlm_cancel from 0@lo arrived at 1771359481 with bad export cookie 3261185172328080463
LustreError: MGC10.0.2.15@tcp: Connection to MGS (at 0@lo) was lost; in progress operations using this service will fail
Lustre: server umount lustre-OST0000 complete
Lustre: server umount lustre-OST0001 complete
LNet: 4100:0:(lib-ptl.c:967:lnet_clear_lazy_portal()) Active lazy portal 0 on exit
LNetError: 4100:0:(acceptor.c:252:lnet_acceptor_remove_socket()) Interface eth0 not found
LNet: Removed LNI 10.0.2.15@tcp
done

========= PASSED llmount in 98s

Passed: llmount
Failed: 
Kernel version: 6.14.0-ktest-171ff02d8a-20260217
TEST SUCCESS
Failed to connect to system scope bus via local transport: No such file or directory
]3008;end=49731cde928b4fb087bd63e0190d0fae\EXT4-fs (vda): re-mounted 88f4410a-2dea-4a38-86ba-3ebc2db2db54 ro. Quota mode: none.
ACPI: PM: Preparing to enter system sleep state S5
reboot: Power down
