UPDATE ROOT IMAGE ... done
P+q6E616D65\[6n[32766;32766H[6n[!p]104[?7h[1G[0J]3008;start=fd452b5e4cf04eaf9e73d75934cb0371;user=root;hostname=lustre-bot-kvm;machineid=a79734507b7a4cd085276a3f8d51378f;bootid=f12fb19d0ea54a639fb7a12f8d8f223d;pid=1;pidfdid=2;comm=systemd;type=boot\Kernel version: 6.14.0-ktest-5102495330-20260217
hook init_noop

Running tests llmount

========= TEST   llmount

SETUP LUSTRE ... libcfs: loading out-of-tree module taints kernel.
libcfs: HW NUMA nodes: 1, HW CPU cores: 16, npartitions: 1
Lustre: Lustre: Build Version: 2.17.50_152_g5102495
LNet: Added LNI 10.0.2.15@tcp [8/256/0/180]
Lustre: Echo OBD driver; http://www.lustre.org/
Lustre: DEBUG MARKER: lustre-bot-kvm: executing set_hostid
Lustre: lustre-MDT0000: mounting server target with '-t lustre' deprecated, use '-t lustre_tgt'
Lustre: ctl-lustre-MDT0000: No data found on store. Initialize space.
Lustre: lustre-MDT0000: new disk, initializing
llog_process_th (2950) used greatest stack depth: 26304 bytes left
Lustre: lustre-MDT0000: Imperative Recovery not enabled, recovery window 300-900
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000200000400-0x0000000240000400]:0:mdt
mount.lustre (2910) used greatest stack depth: 24296 bytes left
Lustre: Modifying parameter general.debug_raw_pointers=Y in log params
mount.lustre (3053) used greatest stack depth: 24160 bytes left
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000240000400-0x0000000280000400]:0:ost
Lustre: cli-lustre-OST0000-super: Allocated super-sequence [0x0000000240000400-0x0000000280000400]:0:ost]
Lustre: lustre-OST0000-osc-MDT0000: update sequence from 0x100000000 to 0x240000400
Lustre: lustre-OST0001-osc-MDT0000: update sequence from 0x100010000 to 0x280000400
Lustre: lustre-MDT0000: local client aa95c94c-443c-4848-bf63-e0e76a8c1685 w/o recovery
Lustre: client wants to enable acl, but mdt not!
Lustre: Mounted lustre-client
Lustre: DEBUG MARKER: Using TIMEOUT=100
Lustre: Setting parameter general.lod.*.mdt_hash=crush in log params
done
CLEANUP LUSTRE ... Lustre: setting import lustre-MDT0000_UUID INACTIVE by administrator request
Lustre: Unmounted lustre-client
Lustre: server umount lustre-MDT0000 complete
LustreError: 3377:0:(ldlm_lockd.c:2564:ldlm_cancel_handler()) ldlm_cancel from 0@lo arrived at 1771358723 with bad export cookie 13846191698823965372
LustreError: MGC10.0.2.15@tcp: Connection to MGS (at 0@lo) was lost; in progress operations using this service will fail
Lustre: server umount lustre-OST0000 complete
Lustre: server umount lustre-OST0001 complete
LNet: 4108:0:(lib-ptl.c:967:lnet_clear_lazy_portal()) Active lazy portal 0 on exit
LNetError: 4108:0:(acceptor.c:252:lnet_acceptor_remove_socket()) Interface eth0 not found
LNet: Removed LNI 10.0.2.15@tcp
done

========= PASSED llmount in 97s

Passed: llmount
Failed: 
Kernel version: 6.14.0-ktest-5102495330-20260217
TEST SUCCESS
Failed to connect to system scope bus via local transport: No such file or directory
]3008;end=fd452b5e4cf04eaf9e73d75934cb0371\EXT4-fs (vda): re-mounted 88f4410a-2dea-4a38-86ba-3ebc2db2db54 ro. Quota mode: none.
ACPI: PM: Preparing to enter system sleep state S5
reboot: Power down
