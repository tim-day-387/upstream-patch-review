UPDATE ROOT IMAGE ... done
P+q6E616D65\[6n[32766;32766H[6n[!p]104[?7h[1G[0J]3008;start=56114ab1b69341558aae074fbe6571a8;user=root;hostname=lustre-bot-kvm;machineid=a79734507b7a4cd085276a3f8d51378f;bootid=fc085f931181433595a9b92a4703850e;pid=1;pidfdid=2;comm=systemd;type=boot\Kernel version: 6.14.0-ktest-c6fd385aa5-20260218
hook init_noop

Running tests llmount

========= TEST   llmount

SETUP LUSTRE ... libcfs: loading out-of-tree module taints kernel.
libcfs: HW NUMA nodes: 1, HW CPU cores: 16, npartitions: 1
Lustre: Lustre: Build Version: 2.17.50_152_gc6fd385
LNet: Added LNI 10.0.2.15@tcp [8/256/0/180]
Lustre: Echo OBD driver; http://www.lustre.org/
Lustre: DEBUG MARKER: lustre-bot-kvm: executing set_hostid
Lustre: lustre-MDT0000: mounting server target with '-t lustre' deprecated, use '-t lustre_tgt'
Lustre: ctl-lustre-MDT0000: No data found on store. Initialize space.
Lustre: lustre-MDT0000: new disk, initializing
Lustre: lustre-MDT0000: Imperative Recovery not enabled, recovery window 300-900
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000200000400-0x0000000240000400]:0:mdt
mount.lustre (2912) used greatest stack depth: 24296 bytes left
Lustre: Modifying parameter general.debug_raw_pointers=Y in log params
Lustre: lustre-OST0000: new disk, initializing
Lustre: srv-lustre-OST0000: No data found on store. Initialize space.
Lustre: Skipped 1 previous similar message
Lustre: lustre-OST0000: Imperative Recovery not enabled, recovery window 300-900
mount.lustre (3055) used greatest stack depth: 23792 bytes left
mount.lustre (3170) used greatest stack depth: 23584 bytes left
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000240000400-0x0000000280000400]:0:ost
Lustre: cli-lustre-OST0000-super: Allocated super-sequence [0x0000000240000400-0x0000000280000400]:0:ost]
Lustre: lustre-OST0000-osc-MDT0000: update sequence from 0x100000000 to 0x240000400
Lustre: lustre-OST0001-osc-MDT0000: update sequence from 0x100010000 to 0x280000400
Lustre: lustre-MDT0000: local client 27aeec9a-7ad2-4bee-95f6-b7236208b8e4 w/o recovery
Lustre: client wants to enable acl, but mdt not!
Lustre: Mounted lustre-client
Lustre: DEBUG MARKER: Using TIMEOUT=100
Lustre: Setting parameter general.lod.*.mdt_hash=crush in log params
done
CLEANUP LUSTRE ... Lustre: setting import lustre-MDT0000_UUID INACTIVE by administrator request
Lustre: Unmounted lustre-client
Lustre: server umount lustre-MDT0000 complete
LustreError: 2915:0:(ldlm_lockd.c:2564:ldlm_cancel_handler()) ldlm_cancel from 0@lo arrived at 1771398078 with bad export cookie 14670147258156800981
LustreError: MGC10.0.2.15@tcp: Connection to MGS (at 0@lo) was lost; in progress operations using this service will fail
Lustre: server umount lustre-OST0000 complete
Lustre: server umount lustre-OST0001 complete
LNet: 4103:0:(lib-ptl.c:967:lnet_clear_lazy_portal()) Active lazy portal 0 on exit
LNetError: 4103:0:(acceptor.c:252:lnet_acceptor_remove_socket()) Interface eth0 not found
LNet: Removed LNI 10.0.2.15@tcp
done

========= PASSED llmount in 97s

Passed: llmount
Failed: 
Kernel version: 6.14.0-ktest-c6fd385aa5-20260218
TEST SUCCESS
Failed to connect to system scope bus via local transport: No such file or directory
]3008;end=56114ab1b69341558aae074fbe6571a8\EXT4-fs (vda): re-mounted 88f4410a-2dea-4a38-86ba-3ebc2db2db54 ro. Quota mode: none.
ACPI: PM: Preparing to enter system sleep state S5
reboot: Power down
