<html lang="en">
<body>
<pre>
From fcb455d815a8002efb5394c78d633c5e10852191 Mon Sep 17 00:00:00 2001
From: Patrick Farrell <pfarrell@whamcloud.com>
Date: Wed, 29 Oct 2025 12:09:42 -0400
Subject: [PATCH 1/1] LU-19536 obdclass: use wait queue for DIO copy sync

Replace spinlock with wait queue in __ll_dio_user_copy
to avoid holding spinlock during operations that can
sleep (page faults, memory context switching, data
copy loops).

The wait queue's internal spinlock is used for brief
state protection. Racing threads wait for the first
thread to complete the copy operation.

Signed-off-by: Patrick Farrell <pfarrell@whamcloud.com>
Change-Id: Ie0adef566cc9007024dff4ada2d8e77a18b02a04
---
 lustre/include/cl_object.h   |  4 +-
 lustre/include/obd_support.h |  1 +
 lustre/obdclass/cl_io.c      | 79 ++++++++++++++++++++++++++++++------
 lustre/tests/sanity.sh       | 34 ++++++++++++++++
 4 files changed, 104 insertions(+), 14 deletions(-)

diff --git a/lustre/include/cl_object.h b/lustre/include/cl_object.h
index 17b8ebeaca..e9848074b5 100644
--- a/lustre/include/cl_object.h
+++ b/lustre/include/cl_object.h
@@ -2635,10 +2635,12 @@ struct cl_sub_dio {
 	struct cl_dio_pages	csd_dio_pages;
 	struct iov_iter		csd_iter;
 	struct cl_iter_dup	csd_dup;
-	spinlock_t		csd_lock;
+	wait_queue_head_t	csd_write_waitq;
+	ssize_t			csd_write_status;
 	unsigned		csd_creator_free:1,
 				csd_write:1,
 				csd_unaligned:1,
+				csd_write_copying:1,
 				csd_write_copied:1;
 };
 
diff --git a/lustre/include/obd_support.h b/lustre/include/obd_support.h
index 0cd0d34507..e432b5218c 100644
--- a/lustre/include/obd_support.h
+++ b/lustre/include/obd_support.h
@@ -643,6 +643,7 @@ extern bool obd_enable_fname_encoding;
 #define OBD_FAIL_LLITE_STATAHEAD_PAUSE		    0x1433
 #define OBD_FAIL_LLITE_STAT_RACE1		    0x1434
 #define OBD_FAIL_LLITE_STAT_RACE2		    0x1435
+#define OBD_FAIL_LLITE_DIO_COPY_ERR		    0x1436
 
 #define OBD_FAIL_FID_INDIR	0x1501
 #define OBD_FAIL_FID_INLMA	0x1502
diff --git a/lustre/obdclass/cl_io.c b/lustre/obdclass/cl_io.c
index d4a9f89f9d..325d07b1f6 100644
--- a/lustre/obdclass/cl_io.c
+++ b/lustre/obdclass/cl_io.c
@@ -1386,7 +1386,7 @@ struct cl_sub_dio *cl_sub_dio_alloc(struct cl_dio_aio *ll_aio,
 		sdio->csd_creator_free = sync;
 		sdio->csd_write = write;
 		sdio->csd_unaligned = unaligned;
-		spin_lock_init(&sdio->csd_lock);
+		init_waitqueue_head(&sdio->csd_write_waitq);
 
 		atomic_add(1,  &ll_aio->cda_sync.csi_sync_nr);
 
@@ -1570,7 +1570,7 @@ static ssize_t __ll_dio_user_copy(struct cl_sub_dio *sdio)
 	size_t original_count = count;
 	int short_copies = 0;
 	bool mm_used = false;
-	bool locked = false;
+	bool do_copy = false;
 	unsigned int i = 0;
 	int status = 0;
 	int rw;
@@ -1587,15 +1587,54 @@ static ssize_t __ll_dio_user_copy(struct cl_sub_dio *sdio)
 	/* read copying is protected by the reference count on the sdio, since
 	 * it's done as part of getting rid of the sdio, but write copying is
 	 * done at the start, where there may be multiple ptlrpcd threads
-	 * using this sdio, so we must lock and check if the copying has
-	 * been done
+	 * using this sdio, so we must synchronize access
 	 */
 	if (rw == WRITE) {
-		spin_lock(&sdio->csd_lock);
-		locked = true;
-		if (sdio->csd_write_copied)
-			GOTO(out, status = 0);
+		unsigned long flags;
+
+		/* Use the wait queue's internal spinlock to protect state.
+		 * We only hold it briefly to check/update flags, not during
+		 * the actual copy operations which can sleep.
+		 */
+		spin_lock_irqsave(&sdio->csd_write_waitq.lock, flags);
+
+		/* Wait if another thread is currently copying */
+		while (sdio->csd_write_copying && !sdio->csd_write_copied) {
+			DEFINE_WAIT(wait);
+
+			prepare_to_wait(&sdio->csd_write_waitq, &wait,
+					TASK_UNINTERRUPTIBLE);
+			spin_unlock_irqrestore(&sdio->csd_write_waitq.lock,
+					       flags);
+
+			schedule();
+
+			spin_lock_irqsave(&sdio->csd_write_waitq.lock, flags);
+			finish_wait(&sdio->csd_write_waitq, &wait);
+		}
+
+		/* If copy is already done (or failed), return the status */
+		if (sdio->csd_write_copied) {
+			ssize_t ret = sdio->csd_write_status;
+
+			spin_unlock_irqrestore(&sdio->csd_write_waitq.lock,
+					       flags);
+			RETURN(ret);
+		}
+
+		/* We're the first thread here, claim the copy operation */
+		sdio->csd_write_copying = true;
+		do_copy = true;
+		spin_unlock_irqrestore(&sdio->csd_write_waitq.lock, flags);
+	} else {
+		/* READ operations don't need synchronization */
+		do_copy = true;
 	}
+
+	/* Only proceed with copy if we're the designated thread */
+	if (!do_copy)
+		RETURN(0);
+
 	/* if there's no mm, io is being done from a kernel thread, so there's
 	 * no need to transition to its mm context anyway.
 	 *
@@ -1619,6 +1658,9 @@ static ssize_t __ll_dio_user_copy(struct cl_sub_dio *sdio)
 			GOTO(out, status = -EFAULT);
 	}
 
+	if (CFS_FAIL_CHECK(OBD_FAIL_LLITE_DIO_COPY_ERR))
+		GOTO(out, status = -EFAULT);
+
 	/* modeled on kernel generic_file_buffered_read/write()
 	 *
 	 * note we only have one 'chunk' of i/o here, so we do not copy the
@@ -1704,9 +1746,6 @@ static ssize_t __ll_dio_user_copy(struct cl_sub_dio *sdio)
 		i++;
 	}
 
-	if (rw == WRITE && status == 0)
-		sdio->csd_write_copied = true;
-
 	/* if we complete successfully, we should reach all of the pages */
 	LASSERTF(ergo(status == 0, i == cdp->cdp_page_count - 1),
 		 "status: %d, i: %d, cdp->cdp_page_count %u, count %zu\n",
@@ -1716,8 +1755,22 @@ out:
 	if (mm_used)
 		kthread_unuse_mm(mm);
 
-	if (locked)
-		spin_unlock(&sdio->csd_lock);
+	/* For write operations, update state and wake any waiting threads */
+	if (rw == WRITE) {
+		unsigned long flags;
+		ssize_t result = original_count - count ? original_count - count : status;
+
+		spin_lock_irqsave(&sdio->csd_write_waitq.lock, flags);
+		/* Store the result (bytes copied or error) for waiting threads */
+		sdio->csd_write_status = result;
+		/* Mark copy as complete (successfully or not) */
+		sdio->csd_write_copied = true;
+		sdio->csd_write_copying = false;
+		spin_unlock_irqrestore(&sdio->csd_write_waitq.lock, flags);
+
+		/* Wake up any threads waiting for the copy to complete */
+		wake_up_all(&sdio->csd_write_waitq);
+	}
 
 	/* the total bytes copied, or status */
 	RETURN(original_count - count ? original_count - count : status);
diff --git a/lustre/tests/sanity.sh b/lustre/tests/sanity.sh
index de900cef85..5501380366 100755
--- a/lustre/tests/sanity.sh
+++ b/lustre/tests/sanity.sh
@@ -15630,6 +15630,40 @@ test_119q()
 }
 run_test 119q "Test patchded Unaligned DIO readv() and writev()"
 
+test_119r() {
+	unaligned_dio_or_skip
+
+	# Test error handling in unaligned DIO user copy with racing threads
+	local file=$DIR/$tfile
+
+	$LFS setstripe -c 2 $file || error "setstripe failed"
+	stack_trap "rm -f $file"
+
+	# Create a file with some data
+	dd if=/dev/urandom of=$file bs=1M count=1 || error "dd failed"
+
+	# Set fail_loc to inject error in DIO copy
+	$LCTL set_param fail_loc=0x1436
+	stack_trap "$LCTL set_param fail_loc=0"
+
+	# Use rwv to do unaligned DIO write at offset 1024 with size 4096
+	# This is unaligned because offset 1024 is not page-aligned
+	local output
+	output=$(rwv -f $file -Dw -n 1 1024 4096 2>&1) &&
+		error "Unaligned DIO write should have failed but succeeded"
+
+	echo "$output" | grep -q "Bad address" ||
+		error "Expected 'Bad address' error, got: $output"
+
+	# Clear fail_loc
+	$LCTL set_param fail_loc=0
+
+	# Verify normal aligned DIO works after error
+	dd if=/dev/zero of=$file bs=4096 count=1 oflag=direct ||
+		error "DIO write failed after clearing fail_loc"
+}
+run_test 119r "Test error handling in unaligned DIO user copy"
+
 test_120a() {
 	[ $PARALLEL == "yes" ] && skip "skip parallel run"
 	remote_mds_nodsh && skip "remote MDS with nodsh"

</pre>
</body>
</html>
