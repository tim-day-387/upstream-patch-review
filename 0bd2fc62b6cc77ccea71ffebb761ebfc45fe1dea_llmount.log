UPDATE ROOT IMAGE ... done
c[?7l[2J[0mSeaBIOS (version 1.15.0-1)


iPXE (https://ipxe.org) 00:01.0 C000 PCI2.10 PnP PMM+7FF8AE10+7FECAE10 C000
Press Ctrl-B to configure iPXE (PCI 00:01.0)...                                                                               


Booting from ROM..c[?7l[2JKernel compiled without mitigations, ignoring 'mitigations'; system may still be vulnerable
P+q6E616D65\[6n[32766;32766H[6n[!p]104[?7h[1G[0J]3008;start=5324aa66d91b4528934cd4763c48ac49;user=root;hostname=lustre-bot-kvm;machineid=a79734507b7a4cd085276a3f8d51378f;bootid=e06e7f84455d44f593d4298ab54b598f;pid=1;pidfdid=2;comm=systemd;type=boot\Kernel version: 6.16.0-ktest-0bd2fc62b6-20260219
hook init_noop

Running tests llmount

========= TEST   llmount
SETUP LUSTRE ... libcfs: loading out-of-tree module taints kernel.
libcfs: HW NUMA nodes: 1, HW CPU cores: 16, npartitions: 1
Lustre: Lustre: Build Version: 2.17.50_152_g0bd2fc6
LNet: Added LNI 10.0.2.15@tcp [8/256/0/180]
Lustre: Echo OBD driver; http://www.lustre.org/
Lustre: DEBUG MARKER: lustre-bot-kvm: executing set_hostid
Lustre: lustre-MDT0000: mounting server target with '-t lustre' deprecated, use '-t lustre_tgt'
Lustre: ctl-lustre-MDT0000: No data found on store. Initialize space.
Lustre: lustre-MDT0000: new disk, initializing
Lustre: lustre-MDT0000: Imperative Recovery not enabled, recovery window 300-900
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000200000400-0x0000000240000400]:0:mdt
mount.lustre (2907) used greatest stack depth: 23704 bytes left
Lustre: Modifying parameter general.debug_raw_pointers=Y in log params
Lustre: lustre-OST0000: new disk, initializing
Lustre: srv-lustre-OST0000: No data found on store. Initialize space.
Lustre: Skipped 1 previous similar message
Lustre: lustre-OST0000: Imperative Recovery not enabled, recovery window 300-900
mount.lustre (3049) used greatest stack depth: 23624 bytes left
Lustre: lustre-MDT0000: local client 072cf0e9-ebc5-4a89-9bf4-51c79043145a w/o recovery
Lustre: client wants to enable acl, but mdt not!
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000240000400-0x0000000280000400]:1:ost
Lustre: Mounted lustre-client
Lustre: cli-lustre-OST0001-super: Allocated super-sequence [0x0000000240000400-0x0000000280000400]:1:ost]
Lustre: lustre-OST0001-osc-MDT0000: update sequence from 0x100010000 to 0x240000400
Lustre: DEBUG MARKER: Using TIMEOUT=100
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000280000400-0x00000002c0000400]:0:ost
Lustre: cli-lustre-OST0000-super: Allocated super-sequence [0x0000000280000400-0x00000002c0000400]:0:ost]
Lustre: lustre-OST0000-osc-MDT0000: update sequence from 0x100000000 to 0x280000400
Lustre: Setting parameter general.lod.*.mdt_hash=crush in log params
done
CLEANUP LUSTRE ... Lustre: setting import lustre-MDT0000_UUID INACTIVE by administrator request
Lustre: Unmounted lustre-client
Lustre: server umount lustre-MDT0000 complete
LustreError: 2910:0:(ldlm_lockd.c:2564:ldlm_cancel_handler()) ldlm_cancel from 0@lo arrived at 1771541569 with bad export cookie 12479599558391299733
LustreError: MGC10.0.2.15@tcp: Connection to MGS (at 0@lo) was lost; in progress operations using this service will fail
Lustre: server umount lustre-OST0000 complete
INFO: task umount:3850 blocked for more than 10 seconds.
      Tainted: G           O        6.16.0-ktest-0bd2fc62b6-20260219 #1
"echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
task:umount          state:R  running task     stack:26864 pid:3850  tgid:3850  ppid:3848   task_flags:0x400100 flags:0x00004002
Call Trace:
 <TASK>
 ? lock_acquire+0xe7/0x1f0
 ? do_raw_spin_lock+0xdf/0x260
 ? cfs_hash_for_each_relax+0x3c3/0xbe0 [obdclass]
 ? ldlm_resource_clean+0xb0/0xb0 [ptlrpc]
 ? cfs_hash_for_each_nolock+0x2d3/0x680 [obdclass]
 ? ldlm_resource_clean+0xb0/0xb0 [ptlrpc]
 ? ldlm_namespace_cleanup+0x85/0x190 [ptlrpc]
 ? qlist_free_all+0xb7/0x160
 ? kasan_quarantine_reduce+0x143/0x160
 ? __kasan_slab_alloc+0x22/0x60
 ? __kmalloc_cache_noprof+0xde/0x260
 ? __kasan_kmalloc+0x72/0x80
 ? lu_context_init+0x281/0x330 [obdclass]
 ? server_put_super+0x294e/0x4d60 [ptlrpc]
 ? _raw_spin_unlock+0x23/0x30
 ? generic_shutdown_super+0x101/0x320
 ? kill_anon_super+0x3d/0x70
 ? deactivate_locked_super+0x95/0xe0
 ? cleanup_mnt+0x1e3/0x3d0
 ? task_work_run+0xff/0x170
 ? exit_to_user_mode_loop+0xa0/0xe0
 ? do_syscall_64+0x150/0x1f0
 ? arch_exit_to_user_mode_prepare+0x9/0x40
 ? entry_SYSCALL_64_after_hwframe+0x4b/0x53
 </TASK>

Showing all locks held in the system:
1 lock held by khungtaskd/99:
 #0: ffffffff8378bb40 (rcu_read_lock){....}-{1:2}, at: debug_show_all_locks+0x29/0xf0
2 locks held by umount/3850:

=============================================

Lustre: server umount lustre-OST0001 complete
LNet: 4114:0:(lib-ptl.c:967:lnet_clear_lazy_portal()) Active lazy portal 0 on exit
LNetError: 4114:0:(acceptor.c:252:lnet_acceptor_remove_socket()) Interface eth0 not found
LNet: Removed LNI 10.0.2.15@tcp
done

========= PASSED llmount in 90s

Passed: llmount
Failed: 
Kernel version: 6.16.0-ktest-0bd2fc62b6-20260219
TEST SUCCESS
Failed to connect to system scope bus via local transport: No such file or directory
]3008;end=5324aa66d91b4528934cd4763c48ac49\EXT4-fs (vda): re-mounted 88f4410a-2dea-4a38-86ba-3ebc2db2db54 ro.
