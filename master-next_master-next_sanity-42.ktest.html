<html lang="en">
<body>
<pre>
P+q6E616D65\[6n[32766;32766H[6n[!p]104[?7h[1G[0J]3008;start=2236ca612bbd449bb17e1194e149b8ec;user=root;hostname=lustre-bot-kvm;machineid=a79734507b7a4cd085276a3f8d51378f;bootid=42dd3aaaa2d24730b8538af5028a7f70;pid=1;pidfdid=2;comm=systemd;type=boot\Kernel version: 6.14.0-ktest
hook init_noop

Running tests sanity-quick

========= TEST   sanity-quick

0a 0b 0c 0d 0e 1 2 3 4 5 6a 6c 6e 6g 6h 6i 7a 7b 8 9 10 11 12 13 14 15 16 17a 17b 17c 17d 17e 17f 17g 17h 17i 17k 17l 17m 17n 17o 17p 17q 18 19a 19b 19c 19d 20 21 22 23a 23b 23c 23d 24a 24b 24c 24d 24e 24f 24g 24h 24i 24j 24k 24l 24m 24n 24o 24p 24q 24r 24s 24t 24u 24v 24w 24x 24y 24z 24A 24B 24C 24E 24F 24G 24H 25a 25b 26a 26b 26c 26d 26e 26f 27a 27b 27ca 27cb 27cc 27cd 27ce 27cf 27cg 27d 27e 27f 27g 27ga 27i 27j 27k 27l 27m 27n 27o 27oo 27p 27q 27r 27s 27t 27u 27v 27w 27wa 27x 27y 27z 27A 27B 27Ca 27Cb 27Cc 27Cd 27Ce 27Cf 27Cg 27Ci 27Cj 27D 27E 27F 27G 27H 27I 27Ia 27J 27K 27L 27M 27N 27O 27P 27Q 27R 27T 27U 27V 27W 27X 28 29 30a 30b 30c 30d 31a 31b 31c 31d 31e 31f 31g 31h 31i 31j 31k 31l 31m 31n 31o 31p 31q 31r 32a 32b 32c 32d 32e 32f 32g 32h 32i 32j 32k 32l 32m 32n 32o 32p 32q 32r 33aa 33a 33b 33c 33d 33e 33f 33g 33h 33hh 33i 33j 34a 34b 34c 34d 34e 34f 34g 34h 35a 36a 36b 36c 36d 36e 36f 36g 36h 36i 38 39a 39b 39c 39d 39e 39f 39g 39h 39i 39j 39k 39l 39m 39n 39o 39p 39r 39q 39s 39u 40 41 42a 42b 42c 42d 42e 43A 43a 43b 43c 44A 44a 44b 44c 44d 44e 44f 44g 45 46 48a 48b 48c 48d 48e 48f 49 50 51a 51b 51c 51d 51e 51f 52a 52b 53 54a 54b 54c 54d 54e 55a 55b 55c 56a 56b 56bb 56bc 56bd 56c 56ca 56d 56e 56g 56h 56i 56ib 56j 56k 56l 56m 56n 56o 56ob 56oc 56od 56oe 56p 56q 56r 56ra 56rb 56rc 56rd 56re 56rf 56s 56t 56u 56v 56wa 56wb 56wc 56wd 56we 56x 56xB 56xC 56xD 56xa 56xab 56xb 56xc 56xd 56xe 56xf 56xg 56xh 56xi 56xj 56xk 56xl 56y 56z 56aa 56ab 56aca 56acb 56acc 56ba 56ca 56da 56db 56dc 56dd 56ea 56eaa 56eab 56eb 56ebb 56ec 56ed 56eda 56edb 56ef 56eg 56eh 56ei 56ej 56ek 57a 57b 58 59 60a 60b 60c 60d 60e 60f 60g 60h 60i 60j 61a 61b 63a 63b 64a 64b 64c 64d 64e 64f 64g 64h 64i 64j 65a 65b 65c 65d 65e 65f 65g 65h 65i 65j 65k 65l 65m 65n 65o 65p 65q 65r 66 69 70a 71 72a 72b 73 74a 74b 74c 76a 76b 77a 77b 77c 77d 77f 77g 77k 77l 77m 77n 77o 78 79 80 81a 81b 99 100 101a 101b 101c 101d 101e 101f 101g 101h 101i 101j 101m 102a 102b 102c 102d 102f 102h 102ha 102i 102j 102k 102l 102m 102n 102p 102q 102r 102s 102t 103a 103b 103c 103e 103f 104a 104b 104c 104d 105a 105b 105c 105d 105e 105f 105g 105h 105i 106 107 110 116a 116b 117 118a 118b 118c 118d 118f 118g 118h 118i 118j 118k 118l 118m 118n 119a 119b 119c 119e 119f 119g 119h 119i 119j 119m 119n 119o 119p 119q 120a 120b 120c 120d 120e 120f 120g 121 123aa 123ab 123ac 123ad 123b 123c 123d 123e 123f 123g 123h 123i 123j 123k 123l 124a 124b 124c 124d 124e 124f 124g 125 126 127a 127b 127c 127d 127e 128 129 130a 130b 130c 130d 130e 130f 130g 130h 130i 131a 131b 131c 131d 131e 133a 133b 133c 133d 133e 133f 133g 133h 134a 134b 135 136 140 150a 150b 150bb 150c 150d 150e 150f 150g 150h 150ia 150ib 150ic 151 152 153 154A 154B 154C 154a 154b 154c 154d 154e 154ea 154f 154g 154h 154i 155a 155b 155c 155d 155e 155f 155g 155h 156 160a 160b 160c 160d 160e 160f 160g 160h 160i 160j 160k 160l 160m 160n 160o 160p 160q 160s 160t 160u 160v 161a 161b 161c 161d 162a 162b 162c 165a 165b 165c 165d 165e 165f 165g 169 170a 170b 171 172 180a 180b 180c 181 182a 182b 183 184a 184b 184c 184d 184e 184f 185 185a 187a 187b 190a 190b 190c 200 204a 204b 204c 204d 204e 204f 204g 204h 205a 205b 205c 205d 205e 205f 205g 205h 205i 205k 205l 205m 206 207a 207b 208 209 210 212 213 214 215 216 217 218 219 220 221 222a 222b 223 224a 224b 224c 224d 225a 225b 226a 226b 226c 226d 226e 227 228a 228b 228c 229 230a 230b 230c 230d 230e 230f 230g 230h 230i 230j 230k 230l 230m 230n 230o 230p 230q 230r 230s 230t 230u 230v 230w 230x 230y 230z 230A 231a 231b 232a 232b 233a 233b 234 235 236 238 239A 239a 239b 240 241a 241b 242 243 244a 244b 245a 245b 247a 247b 247c 247d 247e 247f 247g 247h 248a 248b 248c 249 250 251a 251b 252 253 254 255a 255b 255c 256 257 258a 258b 259 260 270a 270b 270c 270d 270e 270f 270g 270h 270i 270j 271a 271b 271ba 271c 271d 271f 271g 272a 272b 272c 272d 272e 272f 273a 273b 273c 275 276 277 278 280 300a 300b 300c 300d 300e 300f 300g 300h 300i 300j 300k 300l 300m 300n 300o 300p 300q 300r 300s 300t 300ua 300ub 300uc 300ud 300ue 300uf 300ug 300uh 300ui 300uj 310a 310b 310c 311 312 313 314 315 316 317 318 319 350 360 398a 398b 398c 398d 398e 398f 398g 398h 398i 398j 398k 398l 398m 398n 398o 398p 398q 398r 398s 399a 399b 400a 400b 401a 401aa 401ab 401ac 401ad 401b 401c 401d 401db 401e 401f 401ga 401gb 401gc 402 403 404 405 406 407 408 409 410 411a 411b 412 413A 413a 413b 413c 413d 413e 413f 413g 413h 413i 413j 413k 413l 413z 414 415 416 417 418 419 420 421a 421b 421c 421d 421e 421f 421g 421h 422 423 424 425 426 427 428 429 430a 430b 430c 431 432 433 434 440 442 460d 600a 600b 600c 600d 801a 801b 801c 802b 802c 803a 803b 804 805 806 807a 807b 808 809 810 812a 812b 812c 813 814 815 816 817 818 819a 819b 820 823 831 832 833 834 842 850 851 852 853 854 855 860 900 901 902 903 904 905 906 907 908a 908b 909 910
64f 64g 64h 64i 64j 65a 65b 65c 65d 65e
64f,64g,64h,64i,64j,65a,65b,65c,65d,65e
SETUP LUSTRE ... libcfs: loading out-of-tree module taints kernel.
Key type ._llcrypt registered
Key type .llcrypt registered
libcfs: HW NUMA nodes: 1, HW CPU cores: 4, npartitions: 2
Lustre: Lustre: Build Version: 2.16.61_172_g256c062
LNet: Added LNI 10.0.2.15@tcp [8/256/0/180]
Lustre: Echo OBD driver; http://www.lustre.org/
Lustre: DEBUG MARKER: lustre-bot-kvm: executing set_hostid
Lustre: lustre-MDT0000: mounting server target with '-t lustre' deprecated, use '-t lustre_tgt'
Lustre: ctl-lustre-MDT0000: No data found on store. Initialize space.
Lustre: lustre-MDT0000: new disk, initializing
Lustre: lustre-MDT0000: Imperative Recovery not enabled, recovery window 300-900
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000200000400-0x0000000240000400]:0:mdt
mount.lustre (2707) used greatest stack depth: 23536 bytes left
Lustre: Modifying parameter general.debug_raw_pointers=Y in log params
Lustre: lustre-OST0000: new disk, initializing
Lustre: srv-lustre-OST0000: No data found on store. Initialize space.
Lustre: Skipped 1 previous similar message
Lustre: lustre-OST0000: Imperative Recovery not enabled, recovery window 300-900
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000240000400-0x0000000280000400]:0:ost
Lustre: cli-lustre-OST0000-super: Allocated super-sequence [0x0000000240000400-0x0000000280000400]:0:ost]
Lustre: lustre-OST0000-osc-MDT0000: update sequence from 0x100000000 to 0x240000400
Lustre: lustre-MDT0000: local client d517f095-1aa6-4deb-826b-7b378f78b4a1 w/o recovery
Lustre: ctl-lustre-MDT0000: super-sequence allocation rc = 0 [0x0000000280000400-0x00000002c0000400]:1:ost
Lustre: cli-lustre-OST0001-super: Allocated super-sequence [0x0000000280000400-0x00000002c0000400]:1:ost]
Lustre: lustre-OST0001-osc-MDT0000: update sequence from 0x100010000 to 0x280000400
Lustre: client wants to enable acl, but mdt not!
Lustre: Mounted lustre-client
Lustre: DEBUG MARKER: Using TIMEOUT=100
Lustre: Setting parameter general.lod.*.mdt_hash=crush in log params
done
/workspace/lustre-release/lustre/tests/test-framework.sh: line 6803: cd: HOME not set
cat: /etc/system-release: No such file or directory
mgs: 
MGS_OS_ID=debian
MGS_OS_VERSION_CODE=0
MGS_OS_ID_LIKE= debian
cat: /etc/system-release: No such file or directory
mds1: 
MDS1_OS_ID=debian
MDS1_OS_VERSION_CODE=0
MDS1_OS_ID_LIKE= debian
cat: /etc/system-release: No such file or directory
ost1: 
OST1_OS_VERSION_CODE=0
OST1_OS_ID=debian
OST1_OS_ID_LIKE= debian
cat: /etc/system-release: No such file or directory
client: 
CLIENT_OS_ID_LIKE= debian
CLIENT_OS_ID=debian
CLIENT_OS_VERSION_CODE=0
Started at Mon Dec 22 22:04:37 UTC 2025
lustre-bot-kvm: executing check_config_client /mnt/lustre
Lustre: DEBUG MARKER: lustre-bot-kvm: executing check_config_client /mnt/lustre
lustre-bot-kvm: Checking config lustre mounted on /mnt/lustre
Checking servers environments
Checking clients lustre-bot-kvm environments
lustre-bot-kvm: executing check_logdir /tmp/test_logs/2025-12-22/220437
Lustre: DEBUG MARKER: lustre-bot-kvm: executing check_logdir /tmp/test_logs/2025-12-22/220437
Logging to shared log directory: /tmp/test_logs/2025-12-22/220437
lustre-bot-kvm: executing yml_node
Lustre: DEBUG MARKER: lustre-bot-kvm: executing yml_node
Client: 2.16.61.172
Lustre: DEBUG MARKER: Client: 2.16.61.172
MDS: 2.16.61.172
Lustre: DEBUG MARKER: MDS: 2.16.61.172
OSS: 2.16.61.172
Lustre: DEBUG MARKER: OSS: 2.16.61.172
running: sanity ONLY=64f 64g 64h 64i 64j 65a 65b 65c 65d 65e 
run_suite sanity /workspace/lustre-release/lustre/tests/sanity.sh
-----============= acceptance-small: sanity ============----- Mon Dec 22 22:04:38 UTC 2025
Lustre: DEBUG MARKER: -----============= acceptance-small: sanity ============----- Mon Dec 22 22:04:38 UTC 2025
Running: bash /workspace/lustre-release/lustre/tests/sanity.sh
cat: /etc/system-release: No such file or directory
mgs: 
MGS_OS_ID=debian
MGS_OS_VERSION_CODE=0
MGS_OS_ID_LIKE= debian debian
cat: /etc/system-release: No such file or directory
mds1: 
MDS1_OS_ID=debian
MDS1_OS_VERSION_CODE=0
MDS1_OS_ID_LIKE= debian debian
cat: /etc/system-release: No such file or directory
ost1: 
OST1_OS_VERSION_CODE=0
OST1_OS_ID=debian
OST1_OS_ID_LIKE= debian debian
cat: /etc/system-release: No such file or directory
client: 
CLIENT_OS_ID_LIKE= debian debian
CLIENT_OS_ID=debian
CLIENT_OS_VERSION_CODE=0
lustre-bot-kvm: /workspace/lustre-release/lustre/tests/except/sanity.0f.ex
lustre-bot-kvm: /workspace/lustre-release/lustre/tests/except/sanity.ex
- see CLIENT_VERSION > v2_15_63-134-gdacc4b6d38 (34618796 > 34553734) for LU-15963, go 312
- need MDS1_VERSION < v2_14_55-100-g8a84c7f9c7 (34618796 < 34486116) for LU-14927, skip 0f
Lustre: DEBUG MARKER: - need MDS1_VERSION < v2_14_55-100-g8a84c7f9c7 (34618796 < 34486116) for LU-14927, skip 0f
- see MDS1_VERSION <= CLIENT_VERSION (34618796 <= 34618796) for LU-18562, go 270a
- need MDS1_VERSION <= 2.14.55-100-g8a84c7f9c7 (34618796 <= 34486116) for LU-14927, skip 0f
Lustre: DEBUG MARKER: - need MDS1_VERSION <= 2.14.55-100-g8a84c7f9c7 (34618796 <= 34486116) for LU-14927, skip 0f
excepting tests: 442 460d 600a 600b 600c 600d_base 600d 801a 801b 801c 802b 802c 803a 803b 804 805 806 807a 807b 808 809 810 812a 812b 812c 813 814 815 816 817 818 819a 819b 820 823 831 832 833 834 842 850 851 852 853 854 855 860 900 901 902 903 904 905 906 907 908a 908b 909 910 42a 42c 42b 118c 118d 407 119i 817 0f 27A 53 66 270a 119e 119f 119g 119h 156 17o 27oo 27z 27F 60a 64i 232 257 278 280 427 801c 818 820 17a 17b 17e 17g 17i 17p 21 25a 25b 26a 26c 26d 26e 26f 27ga 27Q 28 32e 32f 32g 32h 32m 32n 32o 32p 48a 54a 54c 54d 56l 56m 56n 56rd 56xb 56eb 56eg 56eh 56ei 133a 140 170b 162a 226a 27p 27q 34a 31g 31l 31m 36g 44f 130a 130b 130c 130d 130e 130i 430a 51b 56ab 81b 220 413 418 806 52a 52b 102a 102h 102i 102r 102t 154B 154f 154g 160 161c 161d 205a 65k 807 808 812 56 65e 65a 406 205h 208 165 224d 226d 255 258 272 275 277 311 410 414 419 831 313 314 315 317 200 350 398 399 403 404 408 432 433 398a 405 411 421 27Cg 27U 422 424 425 426 428 429 434 442 430b 430c 431 814 833 850 801a 801b 802b 810 812b 842 851 901 903
Lustre: DEBUG MARKER: excepting tests: 442 460d 600a 600b 600c 600d_base 600d 801a 801b 801c 802b 802c 803a 803b 804 805 806 807a 807b 808 809 810 812a 812b 812c 813 814 815 816 817 818 819a 819b 820 823 831 832 833 834 842 850 851 852 853 854 855 860 900 901 902 903 904 905 9
skipping tests SLOW=no: 27m 60i 64b 68 71 135 136 230d 300o 842
Lustre: DEBUG MARKER: skipping tests SLOW=no: 27m 60i 64b 68 71 135 136 230d 300o 842
=== sanity: start setup 22:04:39 (1766441079) ===
Lustre: DEBUG MARKER: === sanity: start setup 22:04:39 (1766441079) ===
lustre-bot-kvm: executing check_config_client /mnt/lustre
Lustre: DEBUG MARKER: lustre-bot-kvm: executing check_config_client /mnt/lustre
lustre-bot-kvm: Checking config lustre mounted on /mnt/lustre
Checking servers environments
Checking clients lustre-bot-kvm environments
Using TIMEOUT=100
Lustre: DEBUG MARKER: Using TIMEOUT=100
osc.lustre-OST0000-osc-ffff888116ee8000.idle_timeout=debug
osc.lustre-OST0001-osc-ffff888116ee8000.idle_timeout=debug
disable quota as required
Lustre: 5034:0:(mgs_llog.c:1348:mgs_modify_param()) MGS: modify general/lod.*.mdt_hash=crush (mode = 0) failed: rc = -17
=== sanity: finish setup 22:04:40 (1766441080) ===
Lustre: DEBUG MARKER: === sanity: finish setup 22:04:40 (1766441080) ===
running as uid/gid/euid/egid 1000/1000/1000/1000, groups: 1000
 [true]
running as uid/gid/euid/egid 1000/1000/1000/1000, groups: 1000
 [touch] [/mnt/lustre/d0_runas_test/f4174]
preparing for tests involving mounts
mke2fs 1.47.2 (1-Jan-2025)

debug=all

== sanity test 64f: check grant consumption (with grant allocation) ========================================================== 22:04:40 (1766441080)
Lustre: DEBUG MARKER: == sanity test 64f: check grant consumption (with grant allocation) ========================================================== 22:04:40 (1766441080)
debug=+cache
Stopping client lustre-bot-kvm /mnt/lustre (opts:)
LustreError: 5635:0:(lov_obd.c:783:lov_cleanup()) lustre-clilov-ffff888116ee8000: lov tgt 0 not cleaned! deathrow=0, lovrc=1
LustreError: 5635:0:(obd_class.h:479:obd_check_dev()) Device 20 not setup
Lustre: Unmounted lustre-client
Starting client: lustre-bot-kvm:  -o user_xattr,flock 10.0.2.15@tcp:/lustre /mnt/lustre
Lustre: lustre-MDT0000: local client e8a8b34c-3957-4079-81e1-88ce408d4cdd w/o recovery
Lustre: Skipped 2 previous similar messages
Lustre: client wants to enable acl, but mdt not!
Lustre: Mounted lustre-client
1+0 records in
1+0 records out
1765376 bytes (1.8 MB, 1.7 MiB) copied, 0.0186323 s, 94.7 MB/s
Stopping client lustre-bot-kvm /mnt/lustre (opts:)
Starting client: lustre-bot-kvm:  -o user_xattr,flock 10.0.2.15@tcp:/lustre /mnt/lustre
llite.lustre-ffff88814c044000.hybrid_io=0
fail_loc=0x50a
fail_val=3
LustreError: 2729:0:(service.c:2536:ptlrpc_server_handle_request()) @@@ HIT  req@ffff8881111b04c0 x1852247671618816/t0(0) o101->413358d9-cdb1-47aa-a7ed-a2c2edba7370@0@lo:57/0 lens 576/0 e 0 to 0 dl 1766441092 ref 1 fl Interpret:/600/ffffffff rc 0/-1 job:'dd.0' uid:0 gid:0 projid:0
LustreError: 2729:0:(service.c:2537:ptlrpc_server_handle_request()) cfs_fail_timeout id 50a sleeping for 3ms
LustreError: 2729:0:(service.c:2537:ptlrpc_server_handle_request()) cfs_fail_timeout id 50a awake
LustreError: 2722:0:(service.c:2536:ptlrpc_server_handle_request()) @@@ HIT  req@ffff88811674f050 x1852247671620224/t0(0) o501->9f37b571-a806-40ba-bfce-d45d4a93b031@0@lo:57/0 lens 504/0 e 0 to 0 dl 1766441092 ref 1 fl Interpret:/200/ffffffff rc 0/-1 job:'ll_cfg_requeue.0' uid:0 gid:0 projid:4294967295
LustreError: 2722:0:(service.c:2536:ptlrpc_server_handle_request()) Skipped 8 previous similar messages
LustreError: 2722:0:(service.c:2537:ptlrpc_server_handle_request()) cfs_fail_timeout id 50a sleeping for 3ms
LustreError: 2722:0:(service.c:2537:ptlrpc_server_handle_request()) Skipped 8 previous similar messages
1+0 records in
1+0 records out
1765376 bytes (1.8 MB, 1.7 MiB) copied, 0.348772 s, 5.1 MB/s
fail_loc=0
fail_val=0
LustreError: 2722:0:(service.c:2537:ptlrpc_server_handle_request()) cfs_fail_timeout interrupted
PASS 64f (2s)

== sanity test 64g: grant shrink on MDT ================== 22:04:42 (1766441082)
Lustre: DEBUG MARKER: == sanity test 64g: grant shrink on MDT ================== 22:04:42 (1766441082)
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00316983 s, 41.3 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00341271 s, 38.4 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00279341 s, 46.9 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00399316 s, 32.8 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00238777 s, 54.9 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00336439 s, 39.0 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00258355 s, 50.7 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00443526 s, 29.6 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00373485 s, 35.1 MB/s
1+0 records in
1+0 records out
131072 bytes (131 kB, 128 KiB) copied, 0.00329052 s, 39.8 MB/s
396288 grants, 12 pages
396288 grants, 0 pages
396288 grants, 0 pages
396288 grants, 0 pages
mdc.lustre-MDT0000-mdc-ffff88814c044000.grant_shrink_interval=5
0 grants, 0 pages
mdc.lustre-MDT0000-mdc-ffff88814c044000.grant_shrink_interval=1200
PASS 64g (5s)

== sanity test 64h: grant shrink on read ================= 22:04:47 (1766441087)
Lustre: DEBUG MARKER: == sanity test 64h: grant shrink on read ================= 22:04:47 (1766441087)
osc.lustre-OST0000-osc-ffff88814c044000.grant_shrink=1
osc.lustre-OST0000-osc-ffff88814c044000.grant_shrink_interval=10
10+0 records in
10+0 records out
10485760 bytes (10 MB, 10 MiB) copied, 0.42326 s, 24.8 MB/s
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.0207822 s, 197 kB/s
PASS 64h (8s)

== sanity test 64i: shrink on reconnect ================== 22:04:55 (1766441095)
Lustre: DEBUG MARKER: == sanity test 64i: shrink on reconnect ================== 22:04:55 (1766441095)
64+0 records in
64+0 records out
67108864 bytes (67 MB, 64 MiB) copied, 2.56975 s, 26.1 MB/s
fail_loc=0x80000513
fail_val=17
Lustre: *** cfs_fail_loc=513, val=17***
LustreError: 2868:0:(service.c:2319:ptlrpc_server_handle_req_in()) drop incoming rpc opc 17, x1852247671678208
osc.lustre-OST0000-osc-ffff88814c044000.cur_grant_bytes=77775360B
Failing ost1 on lustre-bot-kvm
Stopping /mnt/lustre-ost1 (opts:) on lustre-bot-kvm
Lustre: Failing over lustre-OST0000
LustreError: 6314:0:(obd_class.h:479:obd_check_dev()) Device 12 not setup
LustreError: 6314:0:(obd_class.h:479:obd_check_dev()) Skipped 11 previous similar messages
Lustre: server umount lustre-OST0000 complete
22:05:00 (1766441100) shut down
facet: ost1 facet_host: lustre-bot-kvm facet_failover_host: lustre-bot-kvm
LustreError: lustre-OST0000-osc-MDT0000: operation ost_statfs to node 0@lo failed: rc = -107
Lustre: lustre-OST0000-osc-MDT0000: Connection to lustre-OST0000 (at 0@lo) was lost; in progress operations using this service will wait for recovery to complete
Failover ost1 to lustre-bot-kvm
mount facets: ost1
Start ost1: mount -t lustre -v lustre-wbcfs /mnt/lustre-ost1
LustreError: Server lustre-OST0000 requested index 0, but that index is already in use. Use --writeconf to force
LustreError: 2724:0:(mgs_handler.c:567:mgs_target_reg()) Failed to write lustre-OST0000 log (-98)
Lustre is using wbcfs as backend
OSD_WBC_TGT_TYPE=OST
OSD_WBC_FSNAME=lustre
OSD_WBC_INDEX=0
svname -> lustre:OST0000
OSD_WBC_MGS_NID=10.0.2.15@tcp
params -> mgsnode=10.0.2.15@tcp
LustreError: lustre-OST0000: the MGS refuses to allow this server to start: rc = -98. Please see messages on the MGS.
LustreError: 6409:0:(tgt_mount.c:2483:server_fill_super()) Unable to start targets: -98
LustreError: 6409:0:(tgt_mount.c:1973:server_put_super()) no obd lustre-OST0000
LustreError: 6409:0:(tgt_mount.c:117:server_deregister_mount()) lustre-OST0000 not registered
Lustre: server umount lustre-OST0000 complete
LustreError: 6409:0:(super25.c:199:lustre_fill_super()) llite: Unable to mount <unknown>: rc = -98
mount.lustre: mount -t lustre lustre-wbcfs at /mnt/lustre-ost1 failed: Address already in use retries left: 0
mount.lustre: mount lustre-wbcfs at /mnt/lustre-ost1 failed: Address already in use
The target service's index is already in use. (lustre-wbcfs)
arg[0] = /sbin/mount.lustre
arg[1] = -v
arg[2] = -o
arg[3] = rw
arg[4] = lustre-wbcfs
arg[5] = /mnt/lustre-ost1
source = lustre-wbcfs (lustre-wbcfs), target = /mnt/lustre-ost1
options(2/4096) = rw
checking for existing Lustre data: found
mounting device lustre-wbcfs at /mnt/lustre-ost1, flags=0x1000000 options=osd=osd-wbcfs,mgsnode=10.0.2.15@tcp,virgin,update,svname=lustre-OST0000,device=lustre-wbcfs
Start of -o on ost1 failed 98
 sanity test_64i: @@@@@@ FAIL: Restart of ost1 failed! 
Lustre: DEBUG MARKER: sanity test_64i: @@@@@@ FAIL: Restart of ost1 failed!
  Trace dump:
  = /workspace/lustre-release/lustre/tests/test-framework.sh:7317:error()
  = /workspace/lustre-release/lustre/tests/test-framework.sh:2165:mount_facets()
  = /workspace/lustre-release/lustre/tests/test-framework.sh:4301:facet_failover()
  = /workspace/lustre-release/lustre/tests/test-framework.sh:4420:fail()
  = /workspace/lustre-release/lustre/tests/sanity.sh:11196:test_64i()
  = /workspace/lustre-release/lustre/tests/test-framework.sh:7693:run_one()
  = /workspace/lustre-release/lustre/tests/test-framework.sh:7756:run_one_logged()
  = /workspace/lustre-release/lustre/tests/test-framework.sh:7556:run_test()
  = /workspace/lustre-release/lustre/tests/sanity.sh:11206:main()
Dumping lctl log to /tmp/test_logs/2025-12-22/220437/sanity.test_64i.*.1766441110.log
Dumping logs only on local client.
22:05:11 (1766441111) targets are mounted
22:05:11 (1766441111) facet_failover done
LustreError: lustre-OST0000-osc-ffff88814c044000: operation ost_statfs to node 0@lo failed: rc = -107
Lustre: lustre-OST0000-osc-ffff88814c044000: Connection to lustre-OST0000 (at 0@lo) was lost; in progress operations using this service will wait for recovery to complete
LustreError: 2865:0:(ldlm_lib.c:1179:target_handle_connect()) lustre-OST0000: not available for connect from 0@lo (no target). If you are running an HA pair check that the target is mounted on the other server.
LustreError: 2865:0:(ldlm_lib.c:1179:target_handle_connect()) Skipped 2 previous similar messages
Lustre: 1046:0:(client.c:2478:ptlrpc_expire_one_request()) @@@ Request sent has timed out for slow reply: [sent 1766441099/real 1766441099]  req@ffff88810c7763c0 x1852247671678208/t0(0) o17->lustre-OST0000-osc-ffff88814c044000@0@lo:28/4 lens 456/432 e 0 to 1 dl 1766441115 ref 1 fl Rpc:XQr/200/ffffffff rc 0/-1 job:'lctl.0' uid:0 gid:0 projid:4294967295
LustreError: 2866:0:(ldlm_lib.c:1179:target_handle_connect()) lustre-OST0000: not available for connect from 0@lo (no target). If you are running an HA pair check that the target is mounted on the other server.
LustreError: 2866:0:(ldlm_lib.c:1179:target_handle_connect()) Skipped 1 previous similar message
LustreError: 2867:0:(ldlm_lib.c:1179:target_handle_connect()) lustre-OST0000: not available for connect from 0@lo (no target). If you are running an HA pair check that the target is mounted on the other server.
LustreError: 2867:0:(ldlm_lib.c:1179:target_handle_connect()) Skipped 1 previous similar message
LustreError: 2865:0:(ldlm_lib.c:1179:target_handle_connect()) lustre-OST0000: not available for connect from 0@lo (no target). If you are running an HA pair check that the target is mounted on the other server.
LustreError: 2865:0:(ldlm_lib.c:1179:target_handle_connect()) Skipped 1 previous similar message
LustreError: 2866:0:(ldlm_lib.c:1179:target_handle_connect()) lustre-OST0000: not available for connect from 0@lo (no target). If you are running an HA pair check that the target is mounted on the other server.
LustreError: 2866:0:(ldlm_lib.c:1179:target_handle_connect()) Skipped 2 previous similar messages
LustreError: 2865:0:(ldlm_lib.c:1179:target_handle_connect()) lustre-OST0000: not available for connect from 0@lo (no target). If you are running an HA pair check that the target is mounted on the other server.
LustreError: 2865:0:(ldlm_lib.c:1179:target_handle_connect()) Skipped 4 previous similar messages
</pre>
</body>
</html>
